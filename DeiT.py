# -*- coding: utf-8 -*-
"""Copy of modified_last_kfold_deit_program (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dhfHzKx9D9pR1G9g0W78r5-1fjqGq8Rs
"""

!pip install timm

from google.colab import drive
drive.mount('/content/drive')

!pip install torchvision --upgrade

!pip install transformers

import torch
from torch import nn, optim
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms
from transformers import AutoFeatureExtractor, ViTForImageClassification
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from sklearn.metrics import precision_score, recall_score, f1_score
import gc


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224, scale=(0.5, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # Increased jitter values
        transforms.RandomRotation(30),  # Increased rotation
        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # New addition
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ]),

    'validation': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ]),
    'test': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])
}


data_dir = '/content/drive/MyDrive/combined_dataset'

# Load the entire dataset
entire_dataset = datasets.ImageFolder(data_dir, transform=transforms.ToTensor())

# Calculate sizes for the train, validation, and test datasets
train_size = int(0.7 * len(entire_dataset))
validation_size = (len(entire_dataset) - train_size) // 2
test_size = len(entire_dataset) - train_size - validation_size

# Randomly split the dataset
train_dataset, validation_dataset, test_dataset = torch.utils.data.random_split(
    entire_dataset, [train_size, validation_size, test_size],
    generator=torch.Generator().manual_seed(42)  # Set seed for reproducibility
)

# Update transforms
train_dataset.dataset.transform = data_transforms['train']
validation_dataset.dataset.transform = data_transforms['validation']
test_dataset.dataset.transform = data_transforms['test']

# Create the dataloaders
dataloaders = {
    'train': DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4),
    'validation': DataLoader(validation_dataset, batch_size=8, shuffle=False, num_workers=4),
    'test': DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4),
}
















num_folds = 10
kfold = KFold(n_splits=num_folds, shuffle=True)
num_classes = len(entire_dataset.classes)

feature_extractor = AutoFeatureExtractor.from_pretrained('facebook/deit-tiny-patch16-224')
model = ViTForImageClassification.from_pretrained('facebook/deit-tiny-patch16-224')

# Adding dropout
model.dropout = nn.Dropout(0.7)
model.classifier = nn.Sequential(
    nn.Dropout(0.7),
    nn.Linear(model.config.hidden_size, num_classes)
)

model = model.to(device)

criterion = nn.CrossEntropyLoss()

optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9, weight_decay=0.01)  # Reduced learning rate

lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)


all_train_losses, all_val_losses = [], []
all_train_accuracies, all_val_accuracies = [], []
all_train_precisions, all_val_precisions = [], []
all_train_recalls, all_val_recalls = [], []
all_train_f1_scores, all_val_f1_scores = [], []

def train_model(num_epochs=10):
    global model, criterion, optimizer  # Access global variables
    for fold, (train_ids, val_ids) in enumerate(kfold.split(train_dataset)):

        print(f"\nFOLD {fold+1}")
        print('-' * 10)
        train_subsampler = Subset(train_dataset, train_ids)
        val_subsampler = Subset(train_dataset, val_ids)

        dataloaders = {
            'train': DataLoader(train_subsampler, batch_size=8, shuffle=True, num_workers=4),
            'validation': DataLoader(val_subsampler, batch_size=8, shuffle=False, num_workers=4),
            'test': DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4),
        }

        train_losses, val_losses = [], []
        train_accuracies, val_accuracies = [], []
        train_precisions, val_precisions = [], []
        train_recalls, val_recalls = [], []
        train_f1_scores, val_f1_scores = [], []

        for epoch in range(num_epochs):
            print(f'Epoch {epoch+1}/{num_epochs}')

            for phase in ['train', 'validation']:
                if phase == 'train':
                    model.train()
                else:
                    model.eval()

                running_loss = 0.0
                running_corrects = 0
                epoch_labels = []
                epoch_preds = []

                for inputs, labels in dataloaders[phase]:
                    inputs = inputs.to(device)
                    labels = labels.to(device)

                    optimizer.zero_grad()

                    with torch.set_grad_enabled(phase == 'train'):
                        outputs = model(inputs).logits
                        _, preds = torch.max(outputs, 1)
                        loss = criterion(outputs, labels)

                        if phase == 'train':
                            loss.backward()
                            optimizer.step()

                    running_loss += loss.item() * inputs.size(0)
                    running_corrects += torch.sum(preds == labels.data)
                    epoch_labels.extend(labels.cpu().numpy())
                    epoch_preds.extend(preds.cpu().numpy())

                epoch_loss = running_loss / len(dataloaders[phase].dataset)
                epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)
                epoch_precision = precision_score(epoch_labels, epoch_preds, average='macro')
                epoch_recall = recall_score(epoch_labels, epoch_preds, average='macro')
                epoch_f1 = f1_score(epoch_labels, epoch_preds, average='macro')

                if phase == 'train':
                    train_losses.append(epoch_loss)
                    train_accuracies.append(epoch_acc.item())
                    train_precisions.append(epoch_precision)
                    train_recalls.append(epoch_recall)
                    train_f1_scores.append(epoch_f1)
                else:
                    val_losses.append(epoch_loss)
                    val_accuracies.append(epoch_acc.item())
                    val_precisions.append(epoch_precision)
                    val_recalls.append(epoch_recall)
                    val_f1_scores.append(epoch_f1)

                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Precision: {epoch_precision:.4f} Recall: {epoch_recall:.4f} F1: {epoch_f1:.4f}')

        all_train_losses.append(train_losses)
        all_val_losses.append(val_losses)
        all_train_accuracies.append(train_accuracies)
        all_val_accuracies.append(val_accuracies)
        all_train_precisions.append(train_precisions)
        all_val_precisions.append(val_precisions)
        all_train_recalls.append(train_recalls)
        all_val_recalls.append(val_recalls)
        all_train_f1_scores.append(train_f1_scores)
        all_val_f1_scores.append(val_f1_scores)
        del train_subsampler, val_subsampler, dataloaders
        torch.cuda.empty_cache()
        gc.collect()

    avg_train_losses = [sum(x) / num_folds for x in zip(*all_train_losses)]
    avg_val_losses = [sum(x) / num_folds for x in zip(*all_val_losses)]
    avg_train_accuracies = [sum(x) / num_folds for x in zip(*all_train_accuracies)]
    avg_val_accuracies = [sum(x) / num_folds for x in zip(*all_val_accuracies)]
    avg_train_precisions = [sum(x) / num_folds for x in zip(*all_train_precisions)]
    avg_val_precisions = [sum(x) / num_folds for x in zip(*all_val_precisions)]
    avg_train_recalls = [sum(x) / num_folds for x in zip(*all_train_recalls)]
    avg_val_recalls = [sum(x) / num_folds for x in zip(*all_val_recalls)]
    avg_train_f1_scores = [sum(x) / num_folds for x in zip(*all_train_f1_scores)]
    avg_val_f1_scores = [sum(x) / num_folds for x in zip(*all_val_f1_scores)]

    plt.figure(figsize=(20, 5))

    plt.subplot(1, 5, 1)
    plt.plot(range(1, num_epochs + 1), avg_train_losses, label="Train Loss")
    plt.plot(range(1, num_epochs + 1), avg_val_losses, label="Validation Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()

    plt.subplot(1, 5, 2)
    plt.plot(range(1, num_epochs + 1), avg_train_accuracies, label="Train Accuracy")
    plt.plot(range(1, num_epochs + 1), avg_val_accuracies, label="Validation Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend()

    plt.subplot(1, 5, 3)
    plt.plot(range(1, num_epochs + 1), avg_train_precisions, label="Train Precision")
    plt.plot(range(1, num_epochs + 1), avg_val_precisions, label="Validation Precision")
    plt.xlabel("Epoch")
    plt.ylabel("Precision")
    plt.legend()

    plt.subplot(1, 5, 4)
    plt.plot(range(1, num_epochs + 1), avg_train_recalls, label="Train Recall")
    plt.plot(range(1, num_epochs + 1), avg_val_recalls, label="Validation Recall")
    plt.xlabel("Epoch")
    plt.ylabel("Recall")
    plt.legend()

    plt.subplot(1, 5, 5)
    plt.plot(range(1, num_epochs + 1), avg_train_f1_scores, label="Train F1")
    plt.plot(range(1, num_epochs + 1), avg_val_f1_scores, label="Validation F1")
    plt.xlabel("Epoch")
    plt.ylabel("F1 Score")
    plt.legend()

    plt.tight_layout()
    plt.show()

train_model(num_epochs=10)